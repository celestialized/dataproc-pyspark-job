{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baa1b5cb-a3e8-45f8-9324-79104ae4c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK = 'dataproc'\n",
    "REGION = 'us-central1'\n",
    "\n",
    "GCS_BUCKET = PROJECT_ID\n",
    "GCS_FOLDER = f'demos/{NOTEBOOK}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1636c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT_ID = input('Enter your GCP project ID here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487267db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BQ_DATASET = input('Enter your BQ dataset name here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3f9051-4528-4784-a2db-ea09687afa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0f368c-2913-41f8-9a9d-9f49aa0e1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "gcs = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c44a65-c17e-4700-a553-52884c79145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = NOTEBOOK\n",
    "!rm -rf {NOTEBOOK}\n",
    "!mkdir -p {NOTEBOOK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eabfc45-243a-4492-ba45-38103e0e3e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://fast-envoy-329104/...\n"
     ]
    }
   ],
   "source": [
    "buckets = !gsutil list -p {PROJECT_ID}\n",
    "if f\"gs://{GCS_BUCKET}/\" not in buckets:\n",
    "    ! gsutil mb -l us -c standard gs://{GCS_BUCKET}\n",
    "else: print(f\"Bucket gs://{GCS_BUCKET} already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d731e3-78b1-4c3e-b920-40bed6d08176",
   "metadata": {},
   "source": [
    "### BigQuery Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c5f4c77-c8ab-4425-84c8-cc745dba9ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = bigquery.Dataset(f\"{PROJECT_ID}.{BQ_DATASET}\")\n",
    "ds.location = 'US'\n",
    "ds = bq.create_dataset(dataset = ds, exists_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1af5d-4682-44c5-9b00-1f19ab71ffe4",
   "metadata": {},
   "source": [
    "### Dataproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40c56c4a-2d86-48e8-a577-69aa4f826d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated [https://www.googleapis.com/compute/v1/projects/fast-envoy-329104/regions/us-central1/subnetworks/default].\n",
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n",
      "Private Google Access is Enable = True\n"
     ]
    }
   ],
   "source": [
    "status = !gcloud compute networks subnets describe default --region={REGION} --format=\"get(privateIpGoogleAccess)\"\n",
    "if status[0] == 'False':\n",
    "  !gcloud compute networks subnets update default --region={REGION} --enable-private-ip-google-access\n",
    "  status = !gcloud compute networks subnets describe default --region={REGION} --format=\"get(privateIpGoogleAccess)\"\n",
    "print(f\"Private Google Access is Enable = {status[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a3cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gdc_str.sql', 'r') as f:\n",
    "    sql = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e8ad3d-44c0-4acf-9672-c984735038d9",
   "metadata": {},
   "source": [
    "### Pyspark Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bccc9479-969c-421b-b7c6-65ec6d783e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dataproc/myjob.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {DIR}/myjob.py\n",
    "#!/usr/bin/python\n",
    "\"\"\"BigQuery I/O PySpark example.\"\"\"\n",
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "\n",
    "print(\"Number of Arguments: {0} arguments.\".format(len(sys.argv)))\n",
    "print(\"Arguments List: {0}\".format(str(sys.argv)))\n",
    "\n",
    "# create a session\n",
    "spark = SparkSession.builder.appName('spark-bigquery').getOrCreate()\n",
    "\n",
    "# Use the Cloud Storage bucket for temporary BigQuery export data used by the connector.\n",
    "spark.conf.set('temporaryGcsBucket', sys.argv[1])\n",
    "\n",
    "# Perform word count.\n",
    "query = spark.sql(sql)\n",
    "query.show(n=5)\n",
    "query.printSchema()\n",
    "\n",
    "# Saving the data to BigQuery\n",
    "query.write.format('bigquery').option('table', sys.argv[2]).mode('overwrite').save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67ad9b7-44d9-40da-859a-a4673130c9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [6836e1c7abcf4466aa81ef762b654d27] submitted.\n",
      "Using the default container image\n",
      "unpacking docker.io/library/serverless-spark-default:1.0 (sha256:59f351b542666f6eb713c61aa9e38292daf610ba5489196fbb420c4cbd8f1283)...done\n",
      "Waiting for container log creation\n",
      "PYSPARK_PYTHON=/opt/dataproc/conda/bin/python\n",
      "JAVA_HOME=/usr/lib/jvm/temurin-11-jdk-amd64\n",
      "SPARK_EXTRA_CLASSPATH=\n",
      ":: loading settings :: file = /etc/spark/conf/ivysettings.xml\n",
      "Number of Arguments: 3 arguments.\n",
      "Arguments List: ['/tmp/srvls-batch-d7cbb60e-0508-4594-b6d1-bbc36932b23b/myjob.py', 'fast-envoy-329104/demos/dataproc', 'fast-envoy-329104:dataproc.myjob_output']\n",
      "22/08/22 06:19:23 INFO DirectBigQueryRelation: Querying table bigquery-public-data.samples.shakespeare, parameters sent from Spark: requiredColumns=[word,word_count], filters=[]\n",
      "22/08/22 06:19:23 INFO DirectBigQueryRelation: Going to read from bigquery-public-data.samples.shakespeare columns=[word, word_count], filter=''\n",
      "22/08/22 06:19:25 INFO DirectBigQueryRelation: Created read session for table 'bigquery-public-data.samples.shakespeare': projects/fast-envoy-329104/locations/us/sessions/CAISDFF0UnNtSFNhNTZ1axoCamQaAmpmGgJpchoCb2oaAmpxGgJuYRoCb3MaAm93GgJqchoCaXcaAmpjGgJwehoCcHkaAmpzGgJweBoCb3YaAmppGgJpYRoCaWMaAnBs\n",
      "+----+----------+\n",
      "|word|word_count|\n",
      "+----+----------+\n",
      "| the|     25568|\n",
      "|   I|     21028|\n",
      "| and|     19649|\n",
      "|  to|     17361|\n",
      "|  of|     16438|\n",
      "+----+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- word: string (nullable = false)\n",
      " |-- word_count: long (nullable = true)\n",
      "\n",
      "22/08/22 06:19:34 INFO DirectBigQueryRelation: Querying table bigquery-public-data.samples.shakespeare, parameters sent from Spark: requiredColumns=[word,word_count], filters=[]\n",
      "22/08/22 06:19:34 INFO DirectBigQueryRelation: Going to read from bigquery-public-data.samples.shakespeare columns=[word, word_count], filter=''\n",
      "22/08/22 06:19:35 INFO DirectBigQueryRelation: Created read session for table 'bigquery-public-data.samples.shakespeare': projects/fast-envoy-329104/locations/us/sessions/CAISDGJXbS1wNXdSTElUVhoCamQaAmpmGgJpchoCb2oaAmpxGgJuYRoCb3MaAm93GgJqchoCaXcaAmpjGgJwehoCcHkaAmpzGgJweBoCb3YaAmppGgJpYRoCaWMaAnBs\n",
      "22/08/22 06:19:43 INFO BigQueryClient: Submitted job LoadJobConfiguration{type=LOAD, destinationTable=GenericData{classInfo=[datasetId, projectId, tableId], {datasetId=dataproc, projectId=fast-envoy-329104, tableId=myjob_output}}, decimalTargetTypes=null, destinationEncryptionConfiguration=null, createDisposition=CREATE_IF_NEEDED, writeDisposition=WRITE_TRUNCATE, formatOptions=FormatOptions{format=PARQUET}, nullMarker=null, maxBadRecords=null, schema=null, ignoreUnknownValue=null, sourceUris=[gs://fast-envoy-329104/demos/dataproc/.spark-bigquery-app-20220822061914-0000-7455a085-5bcd-45a3-a1c2-6efaf3f6b05e/part-00000-32ded65f-5263-4eb1-b579-b177df0b5841-c000.snappy.parquet], schemaUpdateOptions=null, autodetect=true, timePartitioning=null, clustering=null, useAvroLogicalTypes=null, labels=null, jobTimeoutMs=null, rangePartitioning=null, hivePartitioningOptions=null}. jobId: JobId{project=fast-envoy-329104, job=f72cfa85-e00d-42c1-a032-8fad22d28ce4, location=US}\n",
      "22/08/22 06:19:46 INFO BigQueryClient: Done loading to fast-envoy-329104.dataproc.myjob_output. jobId: JobId{project=fast-envoy-329104, job=f72cfa85-e00d-42c1-a032-8fad22d28ce4, location=US}\n",
      "Waiting for container to stop\n",
      "Batch [6836e1c7abcf4466aa81ef762b654d27] finished.\n",
      "metadata:\n",
      "  '@type': type.googleapis.com/google.cloud.dataproc.v1.BatchOperationMetadata\n",
      "  batch: projects/fast-envoy-329104/locations/us-central1/batches/6836e1c7abcf4466aa81ef762b654d27\n",
      "  batchUuid: d7cbb60e-0508-4594-b6d1-bbc36932b23b\n",
      "  createTime: '2022-08-22T06:17:59.526102Z'\n",
      "  description: Batch\n",
      "  operationType: BATCH\n",
      "name: projects/fast-envoy-329104/regions/us-central1/operations/f9c9ca91-8874-3d3f-a7eb-6e90bced6def\n"
     ]
    }
   ],
   "source": [
    "!gcloud dataproc batches submit pyspark {DIR}/myjob.py \\\n",
    "--project={PROJECT_ID} \\\n",
    "--region={REGION} \\\n",
    "--deps-bucket={GCS_BUCKET} \\\n",
    "--jars=gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.12-0.24.2.jar \\\n",
    "-- {GCS_BUCKET}/{GCS_FOLDER} \\\n",
    "    {PROJECT_ID}:{BQ_DATASET}.myjob_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fed2f3e-33cf-4f51-91f6-7d036a16cdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>25568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>21028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>19649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>17361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>16438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  word_count\n",
       "0  the       25568\n",
       "1    I       21028\n",
       "2  and       19649\n",
       "3   to       17361\n",
       "4   of       16438"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq.query(query = f\"SELECT * FROM {PROJECT_ID}.{NOTEBOOK}.myjob_output ORDER BY word_count DESC LIMIT 5\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e393c1ce-c6b4-41f0-843d-fc77c8dae94a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
